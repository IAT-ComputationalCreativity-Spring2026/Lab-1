{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9fd12a",
   "metadata": {},
   "source": [
    "# (IAT 460) Week 1 Lab — Introduction to Python, PyTorch, and data modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba11e5",
   "metadata": {},
   "source": [
    "## 1. Lab Objectives\n",
    "\n",
    "This lab is an **introduction to the materials and tools** we will use throughout the course.\n",
    "\n",
    "You are not expected to:\n",
    "\n",
    "- understand all the code\n",
    "\n",
    "- remember every function\n",
    "\n",
    "- optimize anything\n",
    "\n",
    "You are encouraged to:\n",
    "\n",
    "- observe\n",
    "\n",
    "- experiment\n",
    "\n",
    "- discuss\n",
    "\n",
    "- interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bf721",
   "metadata": {},
   "source": [
    "## 2. Libraries\n",
    "\n",
    "Python libraries are collections of tools created by others.\n",
    "\n",
    "Today we will briefly tour several libraries:\n",
    "\n",
    "- **Pillow** (images)\n",
    "\n",
    "- **librosa** (audio)\n",
    "\n",
    "- text processing tools\n",
    "\n",
    "- **pretty_midi** / **symusic** (symbolic music)\n",
    "\n",
    "- **PyTorch** (general-purpose computation & learning)\n",
    "\n",
    "You will later choose **one medium** to experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c49bd6",
   "metadata": {},
   "source": [
    "### Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c70944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "\n",
    "!pip install pillow torch librosa pretty_midi torchvision torchaudio matplotlib \"numpy<2\" datasets llvmlite==0.45.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b54a4",
   "metadata": {},
   "source": [
    "### Download resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/IAT-ComputationalCreativity-Spring2026/Lab-1/raw/refs/heads/main/data.zip\n",
    "!unzip -o data.zip\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a476f",
   "metadata": {},
   "source": [
    "## 3. Images as data (**Pillow**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ddaba",
   "metadata": {},
   "source": [
    "### 3.1 Load and display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = Image.open(\"data/images/sample_image.png\")\n",
    "\n",
    "# Display image information\n",
    "print(\"Image Format:\", img.format)\n",
    "print(\"Image Size:\", img.size)\n",
    "print(\"Image Mode:\", img.mode)\n",
    "\n",
    "def display(img):\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6a90c",
   "metadata": {},
   "source": [
    "### 3.2 Basic Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize an image\n",
    "img = img.resize((256, 256))\n",
    "display(img)\n",
    "\n",
    "# Rotate an image\n",
    "rotated_img = img.rotate(45)\n",
    "display(rotated_img)\n",
    "\n",
    "# Convert image to different modes\n",
    "grayscale_img = img.convert('L')\n",
    "display(grayscale_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1ae24",
   "metadata": {},
   "source": [
    "### 3.3 Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f27cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply built-in filters\n",
    "blurred_img = img.filter(ImageFilter.BLUR)\n",
    "display(blurred_img)\n",
    "\n",
    "sharp_img = img.filter(ImageFilter.SHARPEN)\n",
    "display(sharp_img)\n",
    "\n",
    "edge_enhanced_img = img.filter(ImageFilter.EDGE_ENHANCE)\n",
    "display(edge_enhanced_img)\n",
    "\n",
    "# Create a custom blur\n",
    "custom_blur = ImageFilter.GaussianBlur(radius=10)\n",
    "gaussian_blurred = img.filter(custom_blur)\n",
    "display(gaussian_blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58fbf8",
   "metadata": {},
   "source": [
    "### 3.4 Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b649ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust brightness\n",
    "brightness_enhancer = ImageEnhance.Brightness(img)\n",
    "brightened_img = brightness_enhancer.enhance(5)\n",
    "display(brightened_img)\n",
    "\n",
    "# Adjust contrast\n",
    "contrast_enhancer = ImageEnhance.Contrast(img)\n",
    "high_contrast_img = contrast_enhancer.enhance(5)\n",
    "display(high_contrast_img)\n",
    "\n",
    "# Adjust color\n",
    "color_enhancer = ImageEnhance.Color(img)\n",
    "saturated_img = color_enhancer.enhance(5)\n",
    "display(saturated_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32539b00",
   "metadata": {},
   "source": [
    "### 3.5 Cropping and Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop an image\n",
    "# Syntax: img.crop((left, upper, right, lower))\n",
    "cropped_img = img.crop((100, 100, 300, 300))\n",
    "display(cropped_img)\n",
    "\n",
    "\n",
    "# Paste one image onto another\n",
    "background = Image.new('RGB', (500, 500), color='white')\n",
    "background.paste(cropped_img, (50, 50))\n",
    "display(background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9f416",
   "metadata": {},
   "source": [
    "### 3.6 Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory for outputs if it doesn't exist\n",
    "os.makedirs('outputs/images', exist_ok=True)\n",
    "\n",
    "# Save images in different formats\n",
    "img.save('outputs/images/output_image.png')\n",
    "img.save('outputs/images/output_image.jpg', quality=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a447a",
   "metadata": {},
   "source": [
    "### 3.7 Image Composition and Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dfb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlay = Image.new('RGBA', img.size, (255, 255, 255, 128))\n",
    "blended_img = Image.alpha_composite(img.convert('RGBA'), overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3264d5",
   "metadata": {},
   "source": [
    "### 3.8 Advanced drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8655241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "# Create a drawing context\n",
    "draw_img = img\n",
    "draw = ImageDraw.Draw(draw_img)\n",
    "\n",
    "# Draw a rectangle\n",
    "draw.rectangle([10, 10, 100, 100], outline='red', width=3)\n",
    "display(draw_img)\n",
    "\n",
    "# Draw text\n",
    "draw.text((150, 10), \"Hello, PIL!\", fill='blue')\n",
    "display(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "height, width, channels = 256, 256, 3\n",
    "\n",
    "gradient = np.zeros((height, width), dtype=np.uint8)\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        gradient[i,j] = np.floor((0.5*(i/height)**2 + 0.5*(j/width)**2)**(1/2) * 255)\n",
    "\n",
    "black = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "red_grad = np.stack([gradient, black, black], axis=-1)\n",
    "green_grad = np.stack([black, gradient[::-1,:], black], axis=-1)\n",
    "blue_grad = np.stack([black, black, gradient[:,::-1]], axis=-1)\n",
    "\n",
    "full_grad = red_grad + green_grad + blue_grad\n",
    "\n",
    "red_image = Image.fromarray(red_grad, 'RGB')\n",
    "display(red_image)\n",
    "green_image = Image.fromarray(green_grad, 'RGB')\n",
    "display(green_image)\n",
    "blue_image = Image.fromarray(blue_grad, 'RGB')\n",
    "display(blue_image)\n",
    "full_image = Image.fromarray(full_grad, 'RGB')\n",
    "display(full_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab794f23",
   "metadata": {},
   "source": [
    "## 4. Audio as Data (**librosa**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a887d8",
   "metadata": {},
   "source": [
    "### 4.1 Load Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eaf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "signal, sr = librosa.load(\"data/audio/sample_audio.wav\", sr=None)\n",
    "Audio(signal, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb37c6",
   "metadata": {},
   "source": [
    "### 4.2 Visual representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waveform\n",
    "librosa.display.waveshow(signal, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "S = librosa.amplitude_to_db(np.abs(librosa.stft(signal)))\n",
    "librosa.display.specshow(S, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af58445",
   "metadata": {},
   "source": [
    "### 4.3 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = librosa.feature.spectral_centroid(y=signal, sr=sr)\n",
    "bandwidth = librosa.feature.spectral_bandwidth(y=signal, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr)\n",
    "\n",
    "plt.plot(centroid.T, label=\"Centroid\")\n",
    "plt.plot(bandwidth.T, label=\"Bandwidth\")\n",
    "plt.plot(rolloff.T, label=\"Rolloff\")\n",
    "plt.legend()\n",
    "plt.title(\"Spectral Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = librosa.feature.rms(y=signal)\n",
    "\n",
    "plt.plot(rms.T)\n",
    "plt.title(\"RMS Energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y=signal, sr=sr)\n",
    "\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title(\"Chroma Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270a947",
   "metadata": {},
   "source": [
    "### 4.4 Onset Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_env = librosa.onset.onset_strength(y=signal, sr=sr)\n",
    "\n",
    "plt.plot(onset_env)\n",
    "plt.title(\"Onset Strength Envelope\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b957db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = librosa.onset.onset_detect(\n",
    "    onset_envelope=onset_env,\n",
    "    sr=sr,\n",
    "    units=\"time\"\n",
    ")\n",
    "\n",
    "print(onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.vlines(onsets, -1, 1, color='r', alpha=0.8)\n",
    "plt.title(\"Detected Onsets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf167a",
   "metadata": {},
   "source": [
    "### 4.5 Tempo and beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beats = librosa.beat.beat_track(y=signal, sr=sr)\n",
    "\n",
    "print(f\"Estimated tempo: {tempo[0]:.2f} BPM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_times = librosa.frames_to_time(beats, sr=sr)\n",
    "\n",
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.vlines(beat_times, -1, 1, color='g')\n",
    "plt.title(\"Beat Tracking\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84616900",
   "metadata": {},
   "source": [
    "### 4.6 Audio Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Stretching\n",
    "\n",
    "signal_fast = librosa.effects.time_stretch(signal, rate=1.5)\n",
    "Audio(signal_fast, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cadd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch Shifting\n",
    "\n",
    "signal_pitch_up = librosa.effects.pitch_shift(signal, sr=sr, n_steps=4)\n",
    "Audio(signal_pitch_up, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527b2a0",
   "metadata": {},
   "source": [
    "### 4.7 Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050        # samples per second\n",
    "duration = 2.0   # seconds\n",
    "\n",
    "t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "\n",
    "freq = 440.0  # A4\n",
    "y_sine = 0.5 * np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "Audio(y_sine, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354837ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(y_sine[:1000], sr=sr)\n",
    "plt.title(\"440 Hz Sine Wave\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_square = 0.05 * np.sign(np.sin(2 * np.pi * freq * t))\n",
    "Audio(y_square, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6109d",
   "metadata": {},
   "source": [
    "## 5. Symbolic Music\n",
    "\n",
    "*Credit: https://github.com/craffel/pretty-midi/blob/main/Tutorial.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f02a8c",
   "metadata": {},
   "source": [
    "### 5.1 Creating MIDI from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89655e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7202b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pretty_midi.PrettyMIDI(initial_tempo=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0cb13",
   "metadata": {},
   "source": [
    "### 5.2 Adding a MIDI instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument = pretty_midi.Instrument(\n",
    "    program=pretty_midi.instrument_name_to_program(\"Cello\"),\n",
    "    name=\"Cello\"\n",
    ")\n",
    "\n",
    "pm.instruments.append(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95b1f2",
   "metadata": {},
   "source": [
    "### 5.3 Adding notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee136ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [\n",
    "    (60, 0.0, 0.8),  # C4\n",
    "    (62, 0.8, 1.6),  # D4\n",
    "    (64, 1.6, 2.4),  # E4\n",
    "]\n",
    "\n",
    "for pitch, start, end in notes:\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=90,\n",
    "        pitch=pitch,\n",
    "        start=start,\n",
    "        end=end\n",
    "    )\n",
    "    instrument.notes.append(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63fa0e",
   "metadata": {},
   "source": [
    "### 5.4 Pitch Bends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600379e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 200\n",
    "bend_range = pretty_midi.semitones_to_pitch_bend(1.0)\n",
    "for time, pitch in zip(np.linspace(1.5, 2.3, n_steps),\n",
    "                       range(0, bend_range, bend_range//n_steps)):\n",
    "    instrument.pitch_bends.append(pretty_midi.PitchBend(pitch, time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96412019",
   "metadata": {},
   "source": [
    "### 5.5 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piano_roll(pm, pitch_min=48, pitch_max=72, fs=100):\n",
    "    roll = pm.get_piano_roll(fs=fs)[pitch_min:pitch_max]\n",
    "    librosa.display.specshow(\n",
    "        roll,\n",
    "        hop_length=1,\n",
    "        sr=fs,\n",
    "        x_axis=\"time\",\n",
    "        y_axis=\"cqt_note\",\n",
    "        fmin=pretty_midi.note_number_to_hz(pitch_min)\n",
    "    )\n",
    "    plt.colorbar(label=\"Velocity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68663c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plot_piano_roll(pm)\n",
    "plt.title(\"Piano Roll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3315803",
   "metadata": {},
   "source": [
    "### 5.6 Synthesis (sine waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pm.synthesize(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e55ae4",
   "metadata": {},
   "source": [
    "### 5.7 Saving and opening MIDI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs/MIDI', exist_ok=True)\n",
    "\n",
    "pm.write(\"outputs/MIDI/example_generated.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1aafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pretty_midi.PrettyMIDI(\"data/MIDI/sample_midi.mid\")\n",
    "\n",
    "print(f\"Number of instruments: {len(pm.instruments)}\")\n",
    "print(f\"Total duration: {pm.get_end_time():.2f}s\")\n",
    "\n",
    "for i, inst in enumerate(pm.instruments):\n",
    "    print(f\"Instrument {i}: {inst.name}, notes = {len(inst.notes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8191e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plot_piano_roll(pm)\n",
    "plt.title(\"Piano Roll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pm.synthesize(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cf151",
   "metadata": {},
   "source": [
    "### 5.8 Time, Beats and Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "times, tempi = pm.get_tempo_changes()\n",
    "\n",
    "plt.plot(times, tempi, \".-\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Tempo (BPM)\")\n",
    "plt.title(\"Tempo Changes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7281b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beats = pm.get_beats()\n",
    "downbeats = pm.get_downbeats()\n",
    "\n",
    "print(\"First 5 beats:\", beats[:5])\n",
    "print(\"First 5 downbeats:\", downbeats[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a8803",
   "metadata": {},
   "source": [
    "### 5.9 Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing all notes\n",
    "\n",
    "for inst in pm.instruments:\n",
    "    if inst.is_drum:\n",
    "        continue\n",
    "    for note in inst.notes:\n",
    "        note.pitch += 2\n",
    "\n",
    "# Time stretch\n",
    "\n",
    "length = pm.get_end_time()\n",
    "pm.adjust_times(\n",
    "    original_times=[0, length],\n",
    "    new_times=[0, length * 1.2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pm.synthesize(fs=16000), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb36c8",
   "metadata": {},
   "source": [
    "### 5.10 Harmonic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pm.get_pitch_class_histogram()\n",
    "\n",
    "plt.bar(np.arange(12), hist)\n",
    "plt.xticks(np.arange(12), ['C', '', 'D', '', 'E', 'F', '', 'G', '', 'A', '', 'B'])\n",
    "plt.xlabel(\"Pitch Class\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Pitch Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81171f3",
   "metadata": {},
   "source": [
    "## 6. PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162834ee",
   "metadata": {},
   "source": [
    "### 6.1 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891af15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor from a list\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4])\n",
    "print(\"Tensor from list:\", tensor_from_list)\n",
    "\n",
    "# Create a tensor of zeros\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "print(\"Zeros tensor:\")\n",
    "print(zeros_tensor)\n",
    "\n",
    "# Create a tensor of ones\n",
    "ones_tensor = torch.ones(2, 4)\n",
    "print(\"Ones tensor:\")\n",
    "print(ones_tensor)\n",
    "\n",
    "# Create a random tensor\n",
    "random_tensor = torch.rand(2, 3)\n",
    "print(\"Random tensor:\")\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f848959",
   "metadata": {},
   "source": [
    "### 6.2 Tensor Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor data types\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"Float tensor:\", float_tensor.dtype)\n",
    "\n",
    "int_tensor = torch.tensor([1, 2, 3])\n",
    "print(\"Int tensor:\", int_tensor.dtype)\n",
    "\n",
    "# Convert types\n",
    "converted_tensor = float_tensor.to(torch.int32)\n",
    "print(\"Converted to int32:\", converted_tensor.dtype)\n",
    "\n",
    "# Double precision\n",
    "double_tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
    "print(\"Double tensor:\", double_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4619e6",
   "metadata": {},
   "source": [
    "### 6.3 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Create tensor on CPU\n",
    "cpu_tensor = torch.tensor([1, 2, 3])\n",
    "print(\"CPU tensor device:\", cpu_tensor.device)\n",
    "\n",
    "# Move tensor to device\n",
    "tensor_on_device = cpu_tensor.to(device)\n",
    "print(\"Tensor on device:\", tensor_on_device.device)\n",
    "\n",
    "# If CUDA is available, demonstrate\n",
    "if torch.cuda.is_available():\n",
    "    cuda_tensor = torch.tensor([1, 2, 3]).cuda()\n",
    "    print(\"CUDA tensor device:\", cuda_tensor.device)\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308279f",
   "metadata": {},
   "source": [
    "### 6.4 Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network module\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.linear = nn.Linear(10, 5)  # Simple linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create an instance\n",
    "model = SimpleNet()\n",
    "print(\"Model:\", model)\n",
    "\n",
    "# Create some input\n",
    "input_tensor = torch.randn(1, 10)\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output:\", output)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "print(\"Model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37378d77",
   "metadata": {},
   "source": [
    "## 7. Useful Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0866766",
   "metadata": {},
   "source": [
    "### 7.1 Image Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "flowers = datasets.Flowers102(root='./datasets', split=\"test\", download=True, transform=transform)\n",
    "\n",
    "# Display a sample\n",
    "import matplotlib.pyplot as plt\n",
    "img = flowers[0][0].permute(1,2,0).numpy() * 255\n",
    "img = img.astype(np.uint8)\n",
    "full_image = Image.fromarray(img, 'RGB')\n",
    "display(full_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080cc41",
   "metadata": {},
   "source": [
    "### 7.2 Audio Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919df26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.datasets as audio_datasets\n",
    "\n",
    "# LibriSpeech dataset (speech)\n",
    "yesno_audio = audio_datasets.YESNO(root='./datasets', download=True)\n",
    "print(\"YESNO dataset size:\", len(yesno_audio))\n",
    "\n",
    "# Display sample info\n",
    "waveform, sample_rate, labels = yesno_audio[0]\n",
    "print(\"Sample rate:\", sample_rate)\n",
    "print(\"Waveform shape:\", waveform.shape)\n",
    "\n",
    "Audio(waveform, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c0cbc",
   "metadata": {},
   "source": [
    "### 7.3 Text Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text datasets - using Hugging Face datasets for simplicity\n",
    "from datasets import load_dataset\n",
    "\n",
    "# WikiText-2 dataset\n",
    "ts = load_dataset(\"Trelis/tiny-shakespeare\", split=\"train\")\n",
    "print(\"tiny-shakespeare train size:\", len(ts))\n",
    "\n",
    "# Sample text\n",
    "print(\"Sample text:\", ts[0]['Text'][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadf7e2",
   "metadata": {},
   "source": [
    "### 7.4 MIDI Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "# Load a MIDI file (assuming one exists in data)\n",
    "try:\n",
    "    midi_data = pretty_midi.PrettyMIDI('data/midi/sample.mid')\n",
    "    print(\"MIDI duration:\", midi_data.get_end_time())\n",
    "    print(\"Number of instruments:\", len(midi_data.instruments))\n",
    "    if midi_data.instruments:\n",
    "        print(\"First instrument notes:\", len(midi_data.instruments[0].notes))\n",
    "except FileNotFoundError:\n",
    "    print(\"No MIDI file found. For MIDI datasets, consider:\")\n",
    "    print(\"- MAESTRO dataset (piano performances)\")\n",
    "    print(\"- Lakh MIDI Dataset\")\n",
    "    print(\"- Use pretty_midi to load and manipulate MIDI files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7798a9e",
   "metadata": {},
   "source": [
    "## 8. Creative Transformations with PyTorch Modules\n",
    "\n",
    "In this section, you will pick a modality (image, audio, text, or MIDI) and implement creative transformations using PyTorch's `nn.Module`. The transformations should be encapsulated within a module that can process your chosen data type.\n",
    "\n",
    "### Instructions:\n",
    "1. Choose a modality and dataset (from section 7 or custom data)\n",
    "2. Implement a `Transformation` class that inherits from `nn.Module`\n",
    "3. Define transformations as layers within the module (e.g., rotations, filter, anything you want...)\n",
    "4. Load or generate placeholder data\n",
    "5. Apply the transformations and observe the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e4d37",
   "metadata": {},
   "source": [
    "### 8.1 Placeholder Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Transformation(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Transformation, self).__init__()\n",
    "        # Add arguments here...\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Placeholder forward pass\n",
    "        # implement your transformation logic\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create data or use dataset\n",
    "data = None\n",
    "\n",
    "# Initialize the model\n",
    "model = Transformation()\n",
    "\n",
    "# Apply transformation\n",
    "with torch.no_grad():\n",
    "    transformed_data = model(data)\n",
    "    print(f\"Input data: {data}\")\n",
    "    print(f\"Output data: {transformed_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac852c",
   "metadata": {},
   "source": [
    "### 8.2 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012da1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "BPM = 120\n",
    "SECONDS_PER_BEAT = 60 / BPM\n",
    "\n",
    "N_BARS = 4\n",
    "STEPS_PER_BAR = 16          # 16th notes\n",
    "N_STEPS = N_BARS * STEPS_PER_BAR\n",
    "\n",
    "STEP_DURATION = SECONDS_PER_BEAT / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiTransformation(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: tensor of shape (5,)\n",
    "    Output: pretty_midi.PrettyMIDI object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Musical materials\n",
    "        self.scale = [60, 62, 64, 67, 69]  # C major pentatonic\n",
    "        self.base_velocity = 40\n",
    "        self.max_velocity = 110\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x[0] = density\n",
    "        x[1] = register\n",
    "        x[2] = velocity energy\n",
    "        x[3] = rhythmic variation\n",
    "        x[4] = motif repetition\n",
    "        \"\"\"\n",
    "\n",
    "        density, register, energy, rhythm_var, repetition = x\n",
    "\n",
    "        # Create MIDI container\n",
    "        pm = pretty_midi.PrettyMIDI(initial_tempo=BPM)\n",
    "        instrument = pretty_midi.Instrument(\n",
    "            program=pretty_midi.instrument_name_to_program(\"Electric Piano 1\")\n",
    "        )\n",
    "\n",
    "        # Pitch register mapping\n",
    "        octave_shift = int(register.item() * 3)  # 0–3 octaves\n",
    "        pitch_pool = [p + 12 * octave_shift for p in self.scale]\n",
    "\n",
    "        # Create a repeating motif\n",
    "        motif_length = int(4 + repetition.item() * 8)\n",
    "        motif = torch.randint(0, len(pitch_pool), (motif_length,))\n",
    "\n",
    "        time = 0.0\n",
    "\n",
    "        for step in range(N_STEPS):\n",
    "\n",
    "            # --- NOTE DENSITY ---\n",
    "            if torch.rand(1).item() > density.item():\n",
    "                time += STEP_DURATION\n",
    "                continue  # rest\n",
    "\n",
    "            # --- RHYTHMIC VARIATION ---\n",
    "            duration_factor = 1.0\n",
    "            if torch.rand(1).item() < rhythm_var.item():\n",
    "                duration_factor = np.random.choice(\n",
    "                    torch.tensor([0.5, 1.0, 1.5])\n",
    "                ).item()\n",
    "\n",
    "            duration = STEP_DURATION * duration_factor\n",
    "\n",
    "            # --- MOTIF VS VARIATION ---\n",
    "            if torch.rand(1).item() < repetition.item():\n",
    "                pitch = pitch_pool[motif[step % motif_length]]\n",
    "            else:\n",
    "                pitch = pitch_pool[torch.randint(0, len(pitch_pool), (1,)).item()]\n",
    "\n",
    "            # --- VELOCITY ---\n",
    "            velocity = int(\n",
    "                self.base_velocity +\n",
    "                energy.item() * (self.max_velocity - self.base_velocity) *\n",
    "                torch.rand(1).item()\n",
    "            )\n",
    "\n",
    "            note = pretty_midi.Note(\n",
    "                pitch=int(pitch),\n",
    "                velocity=velocity,\n",
    "                start=time,\n",
    "                end=time + duration\n",
    "            )\n",
    "\n",
    "            instrument.notes.append(note)\n",
    "            time += STEP_DURATION\n",
    "\n",
    "        pm.instruments.append(instrument)\n",
    "        return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6238aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [density, register, energy, rhythm_variation, repetition]\n",
    "control = torch.tensor([\n",
    "    0.7,  # fairly dense\n",
    "    0.4,  # mid register\n",
    "    0.8,  # energetic\n",
    "    0.3,  # mostly straight rhythm\n",
    "    0.6   # some repetition\n",
    "])\n",
    "\n",
    "model = MidiTransformation()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pm = model(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5adb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "roll = pm.get_piano_roll(fs=100)[48:84]\n",
    "librosa.display.specshow(\n",
    "    roll,\n",
    "    sr=100,\n",
    "    hop_length=1,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"cqt_note\",\n",
    "    fmin=pretty_midi.note_number_to_hz(48)\n",
    ")\n",
    "plt.title(\"Rule-Based 4-Bar MIDI Loop\")\n",
    "plt.colorbar(label=\"Velocity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pm.synthesize(fs=16000), rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
